#!/usr/bin/env fkyrun

  Copyright (C) 2023 by
  Dipl.-Ing. Michael Niederle

  This program is free software; you can redistribute it and/or modify
  it under the terms of the GNU Library General Public License, version 2, or
  (at your option) under the terms of the GNU Lesser General Public License,
  version 3.

  This program is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
  GNU Lesser (Library) General Public License for more details.

  For details of the GNU General Public License see the accompanying
  files LGPLv2.txt and LGLPv3.txt or
  http://www.gnu.org/licenses/lgpl-2.0.html
  http://www.gnu.org/licenses/lgpl-3.0.html
  or print to the
  Free Software Foundation, Inc.,
  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.

<require basic/stdlib>
<require basic/export/json>
<require basic/import/json>
<require terminal/terminal>
<require ./ai/llama>

<using std>
<using ai>

<allow unused>

program_parameters!
  $log_level
  list
    VALUED_OPTION "log" 0 to_integer "
      specify the log level (0 = disable)
  $verbose
  list
    "verbose" "
      display the text during generation
  $use_colours
  list
    "colour" "
      use background colours to display the confidence level
  $minimum_confidence
  list
    VALUED_OPTION "min" 15 to_number "
      the minimum confidence value
  $maximum_length
  list
    VALUED_OPTION "length" 1024 to_integer "
      the maximum number of tokens to generate
  $backtrack
  list
    VALUED_OPTION "backtrack" 0 to_integer "
      the maximum number of steps to backtrack
  $stop
  list
    VALUED_OPTION "stop" "
      a substring on which to stop the text generation
  $detailed
  list
    "detailed" "
      request a more detailed answer
  $german
  list
    "german" "
      use a german prompt text
  $model_name
  list
    VALUED_OPTION "model" "vicuna-13b-v1.5.Q4_K_M.gguf" "
      the model to use
  $question
  list
    MANDATORY_PARAMETER "question" "
      the question you want to ask

$do_log log_level > 0

on do_log:
  eprint! "
    model: @(model_name)
    minimum confidence: @(minimum_confidence)
    maximum length: @(maximum_length)
    backtrack: @(backtrack)
    detailed: @(if(detailed (-> "true") (-> "false")))
    log level: @(log_level)
    @;

$DETAILED
  if
    detailed
    -> " detailed"
    -> ""

$DETAILIERT
  if
    detailed
    -> " in ausfÃ¼hrlicher Weise"
    -> ""

load_ai_model! $vicuna model_name

update_if stop.is_defined &stop -> replace_all(stop "\n" = "@nl;")

generate! vicuna $response
  MINIMUM_CONFIDENCE = minimum_confidence
  MAXIMUM_LENGTH = maximum_length
  BACKTRACK = backtrack
  STOP = stop
  LOG_LEVEL = log_level
  VERBOSE = verbose
  USE_COLOURS = use_colours
  if
    german
    ->
      "
	Beantworte die nachstehende Frage@(DETAILIERT) auf deutsch.
	### Frage: @(question)
	### Antwort:@
    ->
      "
	Below is an instruction that describes a task, paired with an input that @
	provides further context. Write a@(DETAILED) response that appropriately @
	completes the request.
	### Instruction: @(question)
	### Response:@

on not(verbose || use_colours): println! response
