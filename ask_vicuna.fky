#!/usr/bin/env fkyrun

<require basic/stdlib>
<require basic/export/json>
<require basic/import/json>
<require terminal/terminal>
<require ./ai/llama>

<using std>
<using ai>

<allow unused>

program_parameters!
  $log_level
  list
    VALUED_OPTION "log" 0 to_integer "
      specify the log level (0 = disable)
  $verbose
  list
    "verbose" "
      display the text during generation
  $use_colours
  list
    "colour" "
      use background colours to display the confidence level
  $minimum_confidence
  list
    VALUED_OPTION "min" 15 to_number "
      the minimum confidence value
  $maximum_length
  list
    VALUED_OPTION "length" 1024 to_integer "
      the maximum number of tokens to generate
  $backtrack
  list
    VALUED_OPTION "backtrack" 0 to_integer "
      the maximum number of steps to backtrack
  $detailed
  list
    "detailed" "
      request a more detailed answer
  $question
  list
    MANDATORY_PARAMETER "question" "
      the question you want to ask

$do_log log_level > 0

on do_log:
  eprint! "
    minimum confidence: @(minimum_confidence)
    maximum length: @(maximum_length)
    backtrack: @(backtrack)
    detailed: @(if(detailed (-> "true") (-> "false")))
    log level: @(log_level)
    @;

$DETAILED
  if
    detailed
    -> " detailed"
    -> ""

load_ai_model! $vicuna "wizard-vicuna-13b.Q4_K_M.gguf"

generate! vicuna $response
  MINIMUM_CONFIDENCE = minimum_confidence
  MAXIMUM_LENGTH = maximum_length
  BACKTRACK = backtrack
  LOG_LEVEL = log_level
  VERBOSE = verbose
  USE_COLOURS = use_colours
  "
    Below is an instruction that describes a task, paired with an input that @
    provides further context. Write a@(DETAILED) response that appropriately @
    completes the request.
    ### Instruction: @(question)
    ### Response:@

println! response
