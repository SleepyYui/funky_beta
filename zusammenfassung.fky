#!/usr/bin/env fkyrun

<require basic/stdlib>
<require basic/export/json>
<require basic/import/json>
<require terminal/terminal>
<require ./ai/llama>

<using std>
<using ai>

program_parameters!
  $log_level
  list
    VALUED_OPTION "log" 0 to_integer "
      specify the log level (0 = disable)
  $verbose
  list
    "verbose" "
      display the text during generation
  $use_colours
  list
    "colour" "
      use background colours to display the confidence level
  $minimum_confidence
  list
    VALUED_OPTION "min" 15 to_number "
      the minimum confidence value
  $maximum_length
  list
    VALUED_OPTION "length" 1024 to_integer "
      the maximum number of tokens to generate
  $backtrack
  list
    VALUED_OPTION "backtrack" 0 to_integer "
      the maximum number of steps to backtrack
  $filename
  list
    MANDATORY_PARAMETER "filename" "
      the name of the file that contains the text to be summarized

load! $text filename
from_utf8 &text

$prompt "
  Fasse den nachstehenden Text in wenigen Zeilen zusammen.
  ### Text: @(text)
  ### Zusammenfassung:@

$do_log log_level > 0

on do_log:
  eprint! "
    minimum confidence: @(minimum_confidence)
    maximum length: @(maximum_length)
    backtrack: @(backtrack)
    log level: @(log_level)
    @;

load_ai_model! $vicuna "synthia-7b-v2.0.Q6_K.gguf"

generate! vicuna $_response
  MINIMUM_CONFIDENCE = minimum_confidence
  MAXIMUM_LENGTH = maximum_length
  BACKTRACK = backtrack
  LOG_LEVEL = log_level
  VERBOSE = verbose
  USE_COLOURS = use_colours
  prompt

pass

#println! response
